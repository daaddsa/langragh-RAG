import os
import requests
import streamlit as st

# Configure Page
st.set_page_config(
    page_title="æ™ºæœç ”æŠ¥åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide"
)

# Constants
API_BASE_URL = "http://localhost:8000"

# Session State Initialization
if "messages" not in st.session_state:
    st.session_state.messages = []
if "session_id" not in st.session_state:
    import uuid
    st.session_state.session_id = str(uuid.uuid4())

# Sidebar Configuration
with st.sidebar:
    st.title("âš™ï¸ è®¾ç½®")
    
    # Add Provider Selector for better UX
    provider = st.selectbox(
        "é€‰æ‹©æ¨¡å‹å‚å•†",
        ["OpenAI", "DeepSeek", "Moonshot (Kimi)", "Aliyun (Qwen)", "Custom"],
        index=0
    )
    
    default_base_urls = {
        "OpenAI": "https://api.openai.com/v1",
        "DeepSeek": "https://api.deepseek.com",
        "Moonshot (Kimi)": "https://api.moonshot.cn/v1",
        "Aliyun (Qwen)": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "Custom": "https://api.openai.com/v1"
    }
    
    default_models = {
        "OpenAI": "gpt-3.5-turbo",
        "DeepSeek": "deepseek-chat",
        "Moonshot (Kimi)": "moonshot-v1-8k",
        "Aliyun (Qwen)": "qwen-plus",
        "Custom": "gpt-3.5-turbo"
    }
    
    base_url = st.text_input("API Base URL", value=default_base_urls[provider])
    model_name = st.text_input("æ¨¡å‹åç§° (Model Name)", value=default_models[provider])
    openai_key = st.text_input("API Key", type="password", help=f"è¯·è¾“å…¥ {provider} çš„ API Key")
    tavily_key = st.text_input("Tavily API Key", type="password")
    
    st.divider()
    if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        import uuid
        st.session_state.session_id = str(uuid.uuid4())
        st.rerun()

    st.divider()
    st.markdown("### ğŸ“¥ å¯¼å‡ºæŠ¥å‘Š")
    report_title = st.text_input("æŠ¥å‘Šæ ‡é¢˜", value="æˆ‘çš„ç ”æŠ¥")
    
    # Initialize session state for PDF if not exists
    if "pdf_data" not in st.session_state:
        st.session_state.pdf_data = None
        
    if st.button("ç”Ÿæˆ PDF"):
        if not st.session_state.messages:
            st.warning("æš‚æ— å¯¹è¯å†…å®¹")
        else:
            with st.spinner("æ­£åœ¨ç”Ÿæˆ PDF..."):
                try:
                    payload = {
                        "session_id": st.session_state.session_id,
                        "title": report_title
                    }
                    resp = requests.post(f"{API_BASE_URL}/pdf", json=payload)
                    if resp.status_code == 200:
                        st.session_state.pdf_data = resp.content
                        st.success("PDF ç”ŸæˆæˆåŠŸï¼")
                    else:
                        st.error(f"ç”Ÿæˆå¤±è´¥: {resp.text}")
                except Exception as e:
                    st.error(f"è¿æ¥é”™è¯¯: {e}")

    # Show download button if data is available
    if st.session_state.pdf_data:
        st.download_button(
            label="ç‚¹å‡»ä¸‹è½½ PDF",
            data=st.session_state.pdf_data,
            file_name=f"{report_title}.pdf",
            mime="application/pdf"
        )

# Main Chat Interface
st.title("ğŸ¤– æ™ºæœç ”æŠ¥åŠ©æ‰‹ (Lite)")
st.caption("åŸºäº LangGraph + Tavily çš„å®æ—¶æœç´¢æ™ºèƒ½ä½“")

# Display History
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Input Handling
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šæœ€æ–°çš„AI Agentè¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿï¼‰"):
    if not openai_key or not tavily_key:
        st.error("è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è®¾ç½® API Keyï¼")
        st.stop()

    # 1. User Message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Assistant Message (Streaming)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        # Show a spinner initially to indicate connection
        with st.spinner("æ­£åœ¨è¿æ¥ Agent..."):
            try:
                # Prepare payload
                payload = {
                    "message": prompt,
                    "session_id": st.session_state.session_id,
                    "openai_api_key": openai_key,
                    "tavily_api_key": tavily_key,
                    "base_url": base_url,
                    "model": model_name
                }
                
                # Stream request
                # Add timeout to prevent indefinite hanging (connect timeout=10s, read timeout=120s)
                # Search operations can be slow, so we increase read timeout.
                with requests.post(f"{API_BASE_URL}/chat", json=payload, stream=True, timeout=(10, 120)) as response:
                    if response.status_code != 200:
                        st.error(f"API Error: {response.text}")
                    else:
                        for chunk in response.iter_content(chunk_size=None):
                            if chunk:
                                try:
                                    text_chunk = chunk.decode("utf-8")
                                    # print(f"DEBUG CHUNK: {text_chunk}") # Frontend debug log
                                    
                                    # Clear initial "Thinking..." message if it's the first real chunk
                                    if full_response == "" and "ğŸ”" in text_chunk:
                                         full_response = text_chunk
                                    else:
                                         full_response += text_chunk
                                    message_placeholder.markdown(full_response + "â–Œ")
                                except Exception as e:
                                    print(f"Error decoding chunk: {e}")
                                
                        message_placeholder.markdown(full_response)
                
                # Save history
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                
            except Exception as e:
                st.error(f"Connection Error: {e}")
